{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš¦ SRIG â€” TabTransformer Model Training\n",
    "### Smart Road India Grid | Model 3 â€” Civic Score Predictor\n",
    "**Yash Jani | Red and White Institute, Surat**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Yeh Model Kaise Kaam Karta Hai?\n",
    "\n",
    "```\n",
    "Driver ka Data (10 features)\n",
    "         â†“\n",
    "   Input Projection\n",
    "   (numbers â†’ vectors)\n",
    "         â†“\n",
    "  Transformer Encoder\n",
    "  (patterns seekhta hai)\n",
    "         â†“\n",
    "  Classification Head\n",
    "  (final decision)\n",
    "         â†“\n",
    "  Risk Level Output\n",
    "  (PLATINUM / GOLD / SILVER / BRONZE / HIGH_RISK)\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Key Concept â€” Transformer kya hota hai?\n",
    "Transformer ek **attention-based** model hai. Matlab yeh automatically samajhta hai ki konsa feature zyada important hai.\n",
    "\n",
    "Example:\n",
    "- `drunk_driving_cases = 2` â†’ Transformer is pe **bahut zyada attention** dega\n",
    "- `city_tier = 1` â†’ Transformer is pe **kam attention** dega\n",
    "\n",
    "Yeh CNN ya simple neural network se zyada smart hota hai! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 1 â€” Libraries Import Karo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Device check â€” GPU hai to GPU, nahi to CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'âœ… Libraries import ho gayi!')\n",
    "print(f'ğŸ’» Device: {device}')\n",
    "print(f'ğŸ”¥ PyTorch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Step 2 â€” Dataset Load Karo\n",
    "\n",
    "Pehle humne jo `civic_score_dataset.csv` banaya tha, use load karenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/civic_score_dataset.csv')\n",
    "\n",
    "print(f'âœ… Dataset loaded!')\n",
    "print(f'   Rows    : {df.shape[0]:,}')\n",
    "print(f'   Columns : {df.shape[1]}')\n",
    "print(f'\\nğŸ“Š Risk Level Distribution:')\n",
    "print(df['risk_level'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 3 â€” Data Preprocessing\n",
    "\n",
    "Model ko raw data directly nahi dete â€” pehle prepare karna padta hai:\n",
    "\n",
    "1. **Label Encoding** â€” `PLATINUM`, `GOLD` etc â†’ `0, 1, 2, 3, 4` (numbers mein)\n",
    "2. **Standard Scaling** â€” sab features ko same range mein laate hain (0 ke around)\n",
    "3. **Train/Test Split** â€” 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    'helmet_compliance_days', 'signal_violations', 'speed_violations',\n",
    "    'school_zone_violations', 'drunk_driving_cases', 'accident_history',\n",
    "    'years_driving', 'training_completed', 'complaints_filed', 'city_tier'\n",
    "]\n",
    "TARGET_COL = 'risk_level'\n",
    "\n",
    "X = df[FEATURE_COLS].values\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "print(f'âœ… Classes: {le.classes_}')\n",
    "print(f'   Encoded as: {list(range(NUM_CLASSES))}')\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f'\\nâœ… Scaling done!')\n",
    "print(f'   Before scaling - Mean: {X[:,0].mean():.1f}, Std: {X[:,0].std():.1f}')\n",
    "print(f'   After scaling  - Mean: {X_scaled[:,0].mean():.2f}, Std: {X_scaled[:,0].std():.2f}')\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "print(f'\\nâœ… Split done!')\n",
    "print(f'   Train samples : {len(X_train):,}')\n",
    "print(f'   Test samples  : {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Step 4 â€” PyTorch Dataset Class Banao\n",
    "\n",
    "PyTorch ko data ek specific format mein chahiye â€” `Dataset` class se batate hain ki data kahan se aayega aur kaise dena hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CivicScoreDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # numpy arrays ko PyTorch tensors mein convert karo\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Dataset objects banao\n",
    "train_dataset = CivicScoreDataset(X_train, y_train)\n",
    "test_dataset  = CivicScoreDataset(X_test,  y_test)\n",
    "\n",
    "# DataLoader â€” batch mein data deta hai model ko\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "print(f'âœ… Dataset ready!')\n",
    "print(f'   Batch size     : 64')\n",
    "print(f'   Train batches  : {len(train_loader)}')\n",
    "print(f'   Test batches   : {len(test_loader)}')\n",
    "\n",
    "# Ek sample dekho\n",
    "sample_X, sample_y = next(iter(train_loader))\n",
    "print(f'\\nğŸ“ Sample batch shape:')\n",
    "print(f'   X shape : {sample_X.shape}  â†’ (64 drivers, 10 features)')\n",
    "print(f'   y shape : {sample_y.shape}  â†’ (64 labels)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 5 â€” TabTransformer Model Define Karo\n",
    "\n",
    "### Architecture Samjho:\n",
    "\n",
    "```\n",
    "Input: [10 features]\n",
    "         â†“\n",
    "Input Projection Layer\n",
    "(10 â†’ 64 dimensions)\n",
    "         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Transformer Layer 1 â”‚  â† Self-Attention + Feed Forward\n",
    "â”‚  Transformer Layer 2 â”‚  â† Self-Attention + Feed Forward  \n",
    "â”‚  Transformer Layer 3 â”‚  â† Self-Attention + Feed Forward\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â†“\n",
    "Layer Normalization\n",
    "         â†“\n",
    "Linear(64 â†’ 64) + ReLU\n",
    "         â†“\n",
    "Linear(64 â†’ 5 classes)\n",
    "         â†“\n",
    "Output: [PLATINUM, GOLD, SILVER, BRONZE, HIGH_RISK]\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Self-Attention kya karta hai?\n",
    "Model khud decide karta hai ki training ke dauran **konse features zyada important hain**. Jaise:\n",
    "- `drunk_driving` â†’ high attention\n",
    "- `city_tier` â†’ low attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, d_model=64, nhead=4, num_layers=3, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "\n",
    "        # Step A: Input ko d_model dimensions mein project karo\n",
    "        # 10 features â†’ 64 dimensional space\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Step B: Transformer Encoder\n",
    "        # nhead=4 matlab 4 alag alag attention heads hain\n",
    "        # Har head alag pattern seekhta hai\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=128,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Step C: Classification Head â€” final prediction karta hai\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)   # (batch, 64)\n",
    "        x = x.unsqueeze(1)             # (batch, 1, 64) â€” sequence format\n",
    "        x = self.transformer(x)        # (batch, 1, 64) â€” attention applied\n",
    "        x = x.squeeze(1)               # (batch, 64)\n",
    "        return self.classifier(x)      # (batch, 5 classes)\n",
    "\n",
    "# Model banao\n",
    "model = TabTransformer(\n",
    "    input_dim=len(FEATURE_COLS),\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "# Model ka summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'âœ… TabTransformer Model Ready!')\n",
    "print(f'   Total Parameters : {total_params:,}')\n",
    "print(f'   Input Features   : {len(FEATURE_COLS)}')\n",
    "print(f'   Output Classes   : {NUM_CLASSES}')\n",
    "print(f'   Device           : {device}')\n",
    "print(f'\\nğŸ—ï¸ Model Architecture:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ Step 6 â€” Model Train Karo\n",
    "\n",
    "### Training kaise hoti hai?\n",
    "```\n",
    "1. Batch of 64 drivers model mein daalo\n",
    "2. Model prediction karta hai\n",
    "3. Loss calculate karo (prediction vs actual)\n",
    "4. Backpropagation â€” model apni galti se seekhta hai\n",
    "5. Weights update karo\n",
    "6. Repeat â†’ 30 epochs tak\n",
    "```\n",
    "\n",
    "**Loss** = model kitna galat hai (kam hona chahiye)\n",
    "\n",
    "**Accuracy** = model kitna sahi hai (zyada hona chahiye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function aur Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "EPOCHS = 30\n",
    "train_losses     = []\n",
    "train_accuracies = []\n",
    "\n",
    "print('ğŸ‹ï¸ Training shuru ho rahi hai...\\n')\n",
    "print(f'{\"Epoch\":<8} {\"Loss\":<12} {\"Accuracy\":<12}')\n",
    "print('-' * 35)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct    = 0\n",
    "    total      = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()           # gradients reset karo\n",
    "        outputs = model(X_batch)        # forward pass\n",
    "        loss = criterion(outputs, y_batch)  # loss calculate karo\n",
    "        loss.backward()                 # backpropagation\n",
    "        optimizer.step()                # weights update karo\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total   += y_batch.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'{epoch+1:<8} {avg_loss:<12.4f} {accuracy:<12.2f}%')\n",
    "\n",
    "print('\\nâœ… Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 7 â€” Training Progress Visualize Karo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('SRIG TabTransformer â€” Training Progress', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Loss Curve\n",
    "axes[0].plot(range(1, EPOCHS+1), train_losses, color='#E74C3C', linewidth=2.5, marker='o', markersize=3)\n",
    "axes[0].set_title('Training Loss (Kam hona chahiye âœ…)', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].fill_between(range(1, EPOCHS+1), train_losses, alpha=0.1, color='red')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy Curve\n",
    "axes[1].plot(range(1, EPOCHS+1), train_accuracies, color='#27AE60', linewidth=2.5, marker='o', markersize=3)\n",
    "axes[1].set_title('Training Accuracy (Zyada hona chahiye âœ…)', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].fill_between(range(1, EPOCHS+1), train_accuracies, alpha=0.1, color='green')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs('models', exist_ok=True)\n",
    "plt.savefig('models/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('âœ… Training curves save ho gayi: models/training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 8 â€” Model Evaluate Karo (Test Data pe)\n",
    "\n",
    "Training ke baad **test data** pe check karte hain ki model ne actual unseen data pe kitna achha perform kiya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds  = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch   = X_batch.to(device)\n",
    "        outputs   = model(X_batch)\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "print(f'ğŸ¯ Test Accuracy: {test_accuracy:.2f}%')\n",
    "print(f'\\nğŸ“‹ Detailed Classification Report:')\n",
    "print(classification_report(all_labels, all_preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Step 9 â€” Confusion Matrix Dekho\n",
    "\n",
    "Confusion matrix se pata chalta hai ki model kahan galti kar raha hai â€” kaun si class ko kaun si class samajh raha hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=le.classes_,\n",
    "    yticklabels=le.classes_\n",
    ")\n",
    "plt.title('SRIG â€” Confusion Matrix\\n(Diagonal pe zyada numbers = achha model)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('âœ… Confusion matrix save ho gayi: models/confusion_matrix.png')\n",
    "print('\\nğŸ’¡ Diagonal values zyada hain = model sahi predict kar raha hai!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 10 â€” Model Save Karo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state':  model.state_dict(),\n",
    "    'label_encoder': le,\n",
    "    'scaler':        scaler,\n",
    "    'feature_cols':  FEATURE_COLS,\n",
    "    'classes':       le.classes_.tolist()\n",
    "}, 'models/civic_score_model.pth')\n",
    "\n",
    "print('ğŸ‰ Model successfully save ho gaya!')\n",
    "print('   ğŸ“ Location : models/civic_score_model.pth')\n",
    "print(f'   ğŸ¯ Accuracy  : {test_accuracy:.2f}%')\n",
    "print('\\nâœ… Ab predict.ipynb run karo aur real predictions dekho!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
